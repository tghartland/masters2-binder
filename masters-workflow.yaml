apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: masters-workflow-
spec:
  entrypoint: masters-workflow
  arguments:
    parameters:
    - name: use-container
      value: gitlab-registry.cern.ch/thartlan/containers/masters2:v1
    # How many pods to run in parallel for each mass point
    - name: expected-limits-parallelism
      value: 4
    # How many expected limits to find per pod
    - name: limits-per-pod
      value: 20

    # Mass points to find limits at
    - name: mass-points
      value: "[2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000]"

    - name: s3-endpoint
      value: "s3.cern.ch"
    - name: s3-secret-name
      value: "s3-cred"
    - name: s3-bucket-name
      value: "argo-bucket"

    - name: redis-host
      value: "redis.redis.svc"
    - name: redis-port
      value: 6379

  templates:
  - name: masters-workflow
    dag:
      tasks:
      - name: init-redis
        template: init-redis

      - name: limits-data
        # Find the upper limit of particle production rate based on the measured dijet distribution
        template: limits-from-data
        dependencies: [init-redis]

      - name: limits-expected
        # Find the expected upper limit of particle production rate based on dijet distributions
        # generated from the theoretical standard model background
        template: expected-limit-at-mass
        arguments:
          parameters:
          - name: mass
            value: "{{item}}"
        withParam: "{{workflow.parameters.mass-points}}"
        dependencies: [init-redis]

      - name: plot
        # Combine the generated expected limits and the limits obtained
        # from the measured data into the final plot
        template: plot
        dependencies: [limits-expected, limits-data]

  - name: init-redis
    container:
      image: gitlab-registry.cern.ch/thartlan/containers/masters-init-redis:v1
      imagePullPolicy: IfNotPresent
      args:
      - "--workflow={{workflow.name}}"
      - "--particle=q*"
      - "--sim-file=QStar/dataLikeHistograms.QStar{0}.root"
      - "--sim-hist=mjj_Scaled_QStar{0}_30fb"
      - "--fb=37"
      - "--masses={{workflow.parameters.mass-points}}"
      - "--redis-host={{workflow.parameters.redis-host}}"
      - "--redis-port={{workflow.parameters.redis-port}}"


  - name: expected-limit-at-mass
    inputs:
      parameters:
      - name: mass
    dag:
      tasks:
      - name: gen-expected-limits
        template: generate-expected-limits
        arguments:
          parameters:
          - name: mass
            value: "{{inputs.parameters.mass}}"
        withSequence:
          count: "{{workflow.parameters.expected-limits-parallelism}}"
          start: 0
      - name: collect-mass-results
        dependencies: [gen-expected-limits]
        template: collect-results
        arguments:
          parameters:
          - name: mass
            value: "{{inputs.parameters.mass}}"

  - name: generate-expected-limits
    inputs:
      parameters:
      - name: mass
    outputs:
      artifacts:
      - name: output
        path: /output
        archive:
          none: {}
        s3:
          bucket: "{{workflow.parameters.s3-bucket-name}}"
          endpoint: "{{workflow.parameters.s3-endpoint}}"
          insecure: false
          key: "{{workflow.name}}/generated/{{inputs.parameters.mass}}"
          accessKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: accessKey
          secretKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: secretKey
    container:
      image: "{{workflow.parameters.use-container}}"
      imagePullPolicy: Always
      resources:
        requests:
          cpu: 850m
      command: [python]
      args:
      - /masters/limit_dist.py
      - "--workflow={{workflow.name}}"
      - "--pod={{pod.name}}"
      - "--mass={{inputs.parameters.mass}}"
      - "--sim-file=QStar/dataLikeHistograms.QStar{0}.root"
      - "--sim-hist=mjj_Scaled_QStar{0}_30fb"
      - "--data-dir=data"
      - "--output-dir=/output"
      - "--successes={{workflow.parameters.limits-per-pod}}"
      - "--redis-host={{workflow.parameters.redis-host}}"
      - "--redis-port={{workflow.parameters.redis-port}}"
    metadata:
      labels:
        masters-workflow/mass: "{{inputs.parameters.mass}}"
    tolerations:
    - key: "virtual-kubelet.io/provider"
      operator: "Exists"

  - name: limits-from-data
    outputs:
      artifacts:
      - name: info
        path: /output
        archive:
          none: {}
        s3:
          bucket: "{{workflow.parameters.s3-bucket-name}}"
          endpoint: "{{workflow.parameters.s3-endpoint}}"
          insecure: false
          key: "{{workflow.name}}/data/"
          accessKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: accessKey
          secretKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: secretKey
    container:
      image: "{{workflow.parameters.use-container}}"
      imagePullPolicy: Always
      resources:
        requests:
          cpu: 1
      command: [python]
      args:
      - /masters/limit_dist_data_qstar.py
      - "--workflow={{workflow.name}}"
      - "--data-dir=data"
      - "--output-dir=/output"
      - "--redis-host={{workflow.parameters.redis-host}}"
      - "--redis-port={{workflow.parameters.redis-port}}"
    tolerations:
    - key: "virtual-kubelet.io/provider"
      operator: "Exists"

  - name: collect-results
    inputs:
      parameters:
        - name: mass
      artifacts:
      - name: data
        path: /data
        s3:
          bucket: "{{workflow.parameters.s3-bucket-name}}"
          endpoint: "{{workflow.parameters.s3-endpoint}}"
          insecure: false
          key: "{{workflow.name}}/generated/{{inputs.parameters.mass}}"
          accessKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: accessKey
          secretKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: secretKey
    outputs:
      artifacts:
      - name: data
        path: /data
        archive:
          none: {}
        s3:
          bucket: "{{workflow.parameters.s3-bucket-name}}"
          endpoint: "{{workflow.parameters.s3-endpoint}}"
          insecure: false
          key: "{{workflow.name}}/generated/{{inputs.parameters.mass}}"
          accessKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: accessKey
          secretKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: secretKey
    container:
      image: alpine:3
      command: [sh, -c]
      args: ["cat /data/* > /data/combined-{{inputs.parameters.mass}}.txt"]
    tolerations:
    - key: "virtual-kubelet.io/provider"
      operator: "Exists"

  - name: plot
    inputs:
      artifacts:
      - name: data
        path: /data
        s3:
          bucket: "{{workflow.parameters.s3-bucket-name}}"
          endpoint: "{{workflow.parameters.s3-endpoint}}"
          insecure: false
          key: "{{workflow.name}}"
          accessKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: accessKey
          secretKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: secretKey
    outputs:
      artifacts:
      - name: data
        path: /data
        archive:
          none: {}
        s3:
          bucket: "{{workflow.parameters.s3-bucket-name}}"
          endpoint: "{{workflow.parameters.s3-endpoint}}"
          insecure: false
          key: "{{workflow.name}}"
          accessKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: accessKey
          secretKeySecret:
            name: "{{workflow.parameters.s3-secret-name}}"
            key: secretKey
    container:
      image: "{{workflow.parameters.use-container}}"
      imagePullPolicy: IfNotPresent
      resources:
        requests:
          cpu: 1
      command: [python]
      args:
      - /masters/plot_brazil.py
      - "--workflow={{workflow.name}}"
      - "--title=q* 95% CL limit brazil plot"
      - "--particle=q*"
      - "--sim-file=QStar/dataLikeHistograms.QStar{0}.root"
      - "--sim-hist=mjj_Scaled_QStar{0}_30fb"
      - "--data-dir=data"
      - "--output-dir=/data/results"
      - "--expected-limit-dir=/data/generated"
      - "--data-limit-dir=/data/data"
      - "--fb=37"
    tolerations:
    - key: "virtual-kubelet.io/provider"
      operator: "Exists"
